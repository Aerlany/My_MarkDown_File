# 大数据技术原理与运用

## 名词解释

## Part 1 大数据技术

**大数据的概念**:数据量大 (Volume), 数据类型繁多 (Variety), 处理速度快 (Velocity), 价值密度低 (Value)

**大数据关键技术**: 数据采集和预处理, 数据储存和管理, 数据处理和分析, 数据安全和隐私保护

**云计算 大数据 物联网 IT 领域最新的发展趋势**

**云计算**: 通过网络提供可伸缩的,廉价的分布式计算能力

**元计算的关键技术**: 虚拟化,分布式存储,分布式计算,多租户

**物联网:** 物联网是物与物之间的连接,它采用局部网络或互联网等通信技术将传感器,控制器,机器,人员通过新的方式连接到一起,实现人物相连,物物相连,实现信息化和远程控制管理.

**物联网技术架构**: 感知层,网络层,处理层,应用层

**大数据与云计算物联网之间的关系**:

1. 云计算为大数据提供技术基础,元计算为物联网提供海量数据存储能力
2. 大数据为云计算提供用武之地, 大数据技术为物联网数据分析提供支撑
3. 物联网是大数据的重要来源, 物联网为云计算提供宽阔的应用空间\

---

## Part 2 Hadoop

**Hadoop**: Hadoop 是一个能够对大量数据进行分布式处理的软件框架具有可靠,高效,可伸缩的特征

## Part 3 HDFS

**分布式文件系统**: (Distributed File System) 是一种通过网络实现文件在多台主机上进行分布式存储的文件系统.分布式文件系统设计一般采用 Client / server (客户机/服务器)模式 分布式文件系统将文件分布存储到多个计算机节点上,成千上万个计算机节点构成计算机集群.

**分布式文件系统的设计目标**:透明性, 并发控制, 可伸缩性,容错和安全

**HDFS 相关概念**:

1. **块**:为了提高磁盘读写效率 HDFS 使用数据块作为单位
2. **名称节点**: (NameNode)负责管理 HDFS 的命名空间(NameSpace), 命名空间包含 FsImage(用于维护文件系统树及其文件树中所有文件和文件夹的元数据); EditLog(用于记录所有针对文件的创建和删除,重命名等文件操作)
3. **数据节点**: (DataNode)分布式文件系统(HDFS)的工作节点, 负责数据的存储和读取.

### HDFS 体系结构

HDFS 采用主从 (Master / Slave) 结构模型, 一个 HDFS 集群包括一个名称节点和若干个数据节点, 名称节点作为中心服务器负责管理文件系统的命名空间及客户端对文件的访问.

### **HDFS 命名空间管理**

命名空间管理指的是命名空间支持对 HDFS 中的目录,文件和块做类似文件系统的创建,修改,删除等操作.整个 HDFS 集群中只有一个命名空间,也就只有一个名称节点,该节点负责对该命名空间进行管理.

### **HDFS 通信协议**

所有的 HDFS 通信协议都是构建在 TCP/IP 协议基础上

### HDFS 存储原理

**数据冗余存储**: 为了保证系统的容错性和可用性,通常一个数据块的多个副本会被分布到不同的数据节点上 优点(加快数据传输速度,容易检查数据错误,保证数据的可靠性)

**数据存储策略**:

1. 数据存放: HDFS 采用以机架(Rack)为基础的数据存放策略.一个 HDFS 集群中通常包含有多个机架, 不同机架之间的数据节点的通信需要经过交换机或路由器, 而同一机架之间的通信则不需要, 这意味着同一机架之间的数据节点的通信带宽较大.
2. **数据读取**: HDFS 提供一个 API 可以确定一个数据节点所属的机架的 ID, 在客户端读取数据时查看同机架是否存在该数据节点的副本, 优先读取同机架的.
3. **数据复制**: 采用流水线复制的策略, 数据优先复制到本地, 切分成若干个块,大小由 HDFS 决定, 在分配到不同的数据节点

### HDFS 数据错误和恢复

1. **名称节点出错**: FsImage 和 EditLog.
2. **数据节点出错**: 每个数据节点会向名称节点定期发送信息,以确保其正常工作.
3. **数据出错**: md5 shal **进行数据校验**

### HDFS 常用命令

```shell
hadoop fs -touchz <PATH> 创建指定<PATH>的空文件
hadoop fs -copyFromLocal <LocalSrc> <dst> 将本地源文件<LocalSrc>复制到HDFS中的<dst>
hadoop fs -copyToLocal <Target> <Localdst> 将HDFS中的<Target>复制到<Localdst>
```

## Part 4 HBase

### HBase 数据模型

HBase 是一个稀疏的,多维度,排序的映射表这张表的索引是行键,列族,列限定符和时间戳, 每个值是一个未经解释的字符串, 没有数据类型;

### HBase 实现原理

1. Master 主服务器: 负责管理和维护 HBase 表的分区信息
2. **表和 Region**: 一个 HBase 储存了许多表, 当表的大小过大时就会将一个数据表分成若干个 Region; (每个 Region 的默认大小是 100MB 到 200Mb, 是 HBase 中负载均衡和数据分发的基本单位)
3. **Region 的定位**: Region 标识符 "表名+开始主键+RegionID" (客户端访问用户数据前需要首先访问 Zookeeper, 获取-ROOT-表的位置信息, 再访问-ROOT-表, 获取.META.表位置信息, 再访问.META.表, 找到 Region 具体在那个 Region 服务器)

HBase 运行机制

1. HBase 系统架构: 客户端, Zookeeper 服务器, Master 服务器, Region 服务器

## Part 5 MapReduce

### Map 函数和 Reduce 函数

Map 和 Region 函数都是以<Key, Value>作为输入, 按一定映射规则转换为另一个或另一批<Key, Value>进行输出

| 函数   | 输入             | 输出          | 说明                                                                                                                                |
| ------ | ---------------- | ------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| Map    | <k1,v1>          | List(<k2,v2>) | (1)将小数据集进一步解析成一批<key,value>,输入到 Map 函数进行处理<br />(2)每一个输入<k1,v1>会输出一批<k2,v2>,<k2,v2>是计算的中间结果 |
| Reduce | List<k2,List(v2) | <k3,v3>       | 输入的中间结果<k2,List(v2)>表示的是一批属于同一个 k2 的 value                                                                       |

​
